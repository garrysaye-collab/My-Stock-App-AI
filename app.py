import streamlit as st
import pandas as pd
import yfinance as yf
import numpy as np
import google.generativeai as genai
import datetime

# ==========================================
# ğŸ”§ ç³»çµ±è¨­å®šèˆ‡ç‹€æ…‹åˆå§‹åŒ–
# ==========================================
st.set_page_config(page_title="Gemini 2.5 Pro æˆ°æƒ…å®¤", page_icon="ğŸ“ˆ", layout="wide")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "data_context" not in st.session_state:
    st.session_state.data_context = None

# ==========================================
# ğŸ“Š é€²éšé‡åŒ–è¨ˆç®—èˆ‡å›æ¸¬
# ==========================================
def calculate_advanced_metrics(df, log_df):
    """è¨ˆç®—å¤æ™®æ¯”ç‡èˆ‡æœ€å¤§å›æ’¤"""
    if log_df.empty:
        return 0, 0
    
    # ç°¡å–® Sharpe Ratio ä¼°ç®— (å¹´åŒ–)
    returns = log_df['ç²åˆ©%'] / 100
    sharpe = (returns.mean() / returns.std() * np.sqrt(252)) if len(returns) > 1 else 0
    
    # æœ€å¤§å›æ’¤ (MDD)
    cum_rets = (1 + returns).cumprod()
    peak = cum_rets.cummax()
    mdd = ((cum_rets - peak) / peak).min() * 100
    
    return round(sharpe, 2), round(mdd, 2)

@st.cache_data(ttl=300)
def get_data_engine(symbol):
    symbol = symbol.strip().upper()
    if symbol.isdigit(): symbol = f"{symbol}.TW"
    elif not any(s in symbol for s in [".TW", ".TWO", ".HK", ".US", ".SS", ".SZ"]):
        if not (symbol.isalpha() and len(symbol) <= 4): symbol = f"{symbol}.TW"
    
    try:
        t = yf.Ticker(symbol)
        df = t.history(period="2y")
        if df.empty: return None, None, symbol, "æŸ¥ç„¡æ•¸æ“š"
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        # æŒ‡æ¨™è£œå®Œ
        df['MA5'] = df['Close'].rolling(5).mean()
        df['MA10'] = df['Close'].rolling(10).mean()
        df['MA20'] = df['Close'].rolling(20).mean()
        df['DIF'] = df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()
        df['MACD'] = df['DIF'].ewm(span=9).mean()
        df['OSC'] = df['DIF'] - df['MACD']
        df['ATR'] = (df['High'] - df['Low']).rolling(14).mean()
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / loss.replace(0, np.nan)
        df['RSI'] = 100 - (100 / (1 + rs))
        
        return df.dropna(), t.info.get('longName', symbol), symbol, None
    except Exception as e:
        return None, None, symbol, str(e)

# ==========================================
# ğŸ¤– Gemini 2.5 Flash æ™ºèƒ½æ ¸å¿ƒ (å„ªå…ˆèª¿ç”¨)
# ==========================================
def get_gemini_25_response(api_key, messages_history):
    genai.configure(api_key=api_key)
    
    # å¼·åˆ¶å„ªå…ˆç´šï¼š2.5 Flash > 2.0 Flash > 1.5 Pro
    priority_models = [
        "gemini-2.5-flash", 
        "gemini-2.0-flash", 
        "gemini-1.5-pro"
    ]
    
    # åµæ¸¬å¯ç”¨æ¨¡å‹
    available = [m.name.replace("models/", "") for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    target_model = next((m for m in priority_models if m in available), "gemini-1.5-flash")

    sys_instruction = f"""
    ç¾åœ¨æ˜¯ {datetime.datetime.now().strftime("%Y-%m-%d")}ã€‚ä½ æ˜¯é…å‚™ Gemini 2.5 Flash çš„é ‚ç´šå°æ²–åŸºé‡‘ç¶“ç†ã€‚
    
    ã€èƒ½åŠ›ã€‘
    1. ä½¿ç”¨ Google Search æŠ“å–ä»Šæ—¥å³æ™‚è²¡å ±ã€æ³•èªªæœƒè¨Šæ¯èˆ‡åœ‹éš›å±€å‹¢ã€‚
    2. ä½¿ç”¨ GEM (Global Economic Monitor) æ¡†æ¶ï¼š
       - **ğŸŒŠ è³‡é‡‘æµªæ½®**ï¼šåˆ†æç±Œç¢¼é¢èˆ‡å¸‚å ´æµå‹•æ€§ã€‚
       - **ğŸŒ‹ çµæ§‹é¢¨éšª**ï¼šåˆ©ç”¨ç©ºæ–¹è¦–è§’æŒ‡å‡ºæ½›åœ¨æŠ€è¡“å´©æ½°é»ã€‚
       - **ğŸ­ èŠå®¶åšå¼ˆ**ï¼šæ‹†è§£å¤§æˆ¶æ´—ç›¤æˆ–èª˜å¤šé™·é˜±ã€‚
       - **ğŸ† æœ€çµ‚å‹ç®—**ï¼šç¶œåˆé‡åŒ–å¾—åˆ†ï¼Œçµ¦å‡ºã€ŒæŠ•è³‡å»ºè­°è©•ç­‰ã€ã€‚
    """

    try:
        model = genai.GenerativeModel(
            model_name=target_model,
            tools=[{"google_search_retrieval": {}}],
            system_instruction=sys_instruction
        )
        
        # è½‰æ›æ­·å²è¨Šæ¯æ ¼å¼
        history = []
        for m in messages_history[:-1]:
            role = "user" if m["role"] == "user" else "model"
            history.append({"role": role, "parts": [m["content"]]})
        
        chat = model.start_chat(history=history)
        # Gemini 2.5 Flash å›æ‡‰
        response = chat.send_message(messages_history[-1]["content"])
        return response.text, target_model
    except Exception as e:
        return f"âŒ AI æœå‹™ç•°å¸¸: {str(e)}", "N/A"

# ==========================================
# ğŸ–¥ï¸ UI ä»‹é¢
# ==========================================
with st.sidebar:
    st.title("ğŸ¦ æ™ºåº«æ§åˆ¶ä¸­å¿ƒ")
    key = st.text_input("Gemini API Key", type="password")
    ticker = st.text_input("è‚¡ç¥¨ä»£è™Ÿ", value="AAPL")
    scan_btn = st.button("å•Ÿå‹•å…¨æ•¸æ“šæƒæ", type="primary", use_container_width=True)
    if st.button("é‡ç½®å°è©±"): st.session_state.messages = []; st.rerun()

if scan_btn and key:
    with st.spinner("ğŸš€ Gemini 2.5 æ­£åœ¨èª¿é–±å…¨çƒæ•¸æ“šèˆ‡å›æ¸¬åˆ†æ..."):
        df, name, sid, err = get_data_engine(ticker)
        if df is not None:
            # é‡åŒ–è©•åˆ†èˆ‡å›æ¸¬ (æ²¿ç”¨ä½ çš„é‚è¼¯ä½†è£œå¼·)
            from __main__ import detailed_scoring, comprehensive_backtest # ç¢ºä¿èƒ½æŠ“åˆ°ä¸‹æ–¹å®šç¾©
            score, score_df = detailed_scoring(df)
            bt_log = comprehensive_backtest(df)
            sharpe, mdd = calculate_advanced_metrics(df, bt_log)
            
            # å­˜å…¥ç’°å¢ƒ
            st.session_state.data_context = {
                "df": df, "name": name, "sid": sid, "score": score, 
                "score_df": score_df, "bt_log": bt_log, "sharpe": sharpe, "mdd": mdd
            }
            
            # åˆå§‹ Prompt
            prompt = f"åˆ†æ {name} ({sid})ã€‚è©•åˆ†:{score}/10, å¤æ™®å€¼:{sharpe}, æœ€å¤§å›æ’¤:{mdd}%ã€‚è«‹è¯ç¶²æª¢ç´¢ä»Šæ—¥æœ€æ–°é‡å¤§æ–°èã€‚"
            ai_resp, used_model = get_gemini_25_response(key, [{"role": "user", "content": prompt}])
            
            st.session_state.messages = [
                {"role": "user", "content": f"å•Ÿå‹• {sid} æ·±åº¦æƒæå ±å‘Š"},
                {"role": "assistant", "content": ai_resp}
            ]
            st.session_state.used_model = used_model
        else:
            st.error(err)

# é¡¯ç¤ºçœ‹æ¿
if st.session_state.data_context:
    ctx = st.session_state.data_context
    st.header(f"ğŸ“Š {ctx['name']} ({ctx['sid']})")
    
    # é ‚éƒ¨æŒ‡æ¨™
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("å‹•èƒ½è©•åˆ†", f"{ctx['score']} / 10")
    m2.metric("å¤æ™®æ¯”ç‡ (Sharpe)", ctx['sharpe'])
    m3.metric("æœ€å¤§å›æ’¤ (MDD)", f"{ctx['mdd']}%")
    m4.metric("ä½¿ç”¨æ¨¡å‹", st.session_state.used_model)

    # åœ–è¡¨å€
    st.line_chart(ctx['df'][['Close', 'MA20']].tail(120))
    
    with st.expander("ğŸ“ æŸ¥çœ‹è©³ç´°æŒ‡æ¨™èˆ‡å›æ¸¬å°å¸³å–®"):
        c_a, c_b = st.columns(2)
        c_a.table(ctx['score_df'])
        c_b.dataframe(ctx['bt_log'])

    st.divider()
    
    # å°è©±å€
    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    if query := st.chat_input("è©¢å• AI ç¶“ç†äºº..."):
        st.session_state.messages.append({"role": "user", "content": query})
        st.chat_message("user").markdown(query)
        with st.chat_message("assistant"):
            with st.spinner("æ™ºåº«è¾¯è­‰ä¸­..."):
                resp, _ = get_gemini_25_response(key, st.session_state.messages)
                st.markdown(resp)
                st.session_state.messages.append({"role": "assistant", "content": resp})

# åŸæœ‰å‡½æ•¸éœ€æ”¾åœ¨åŒä¸€æ–‡ä»¶æˆ– import
def slope(series, n=3):
    y = series.tail(n).dropna()
    if len(y) < n: return 0
    return np.polyfit(np.arange(len(y)), y, 1)[0]

def detailed_scoring(df):
    r = df.iloc[-1]
    details = []
    total_score = 0
    checks = [
        (r['MA5'] > r['MA10'] > r['MA20'], 3, "å‡ç·šå¤šé ­", "MA5>10>20"),
        (slope(df['DIF']) > 0 and r['OSC'] > 0, 2, "MACDè½‰å¼·", "DIFæ–œç‡>0"),
        (r['Close'] > r['MA20'], 1, "ç«™ä¸Šæœˆç·š", "Close > MA20"),
        (r['Volume'] > df['Volume'].tail(5).mean(), 1, "é‡èƒ½å¢æº«", "Vol > 5MA")
    ]
    for cond, pts, rule, desc in checks:
        s = pts if cond else 0
        details.append({"æº–å‰‡": rule, "å¾—åˆ†": s, "ç‹€æ…‹": "âœ…" if cond else "âŒ"})
        total_score += s
    return total_score, pd.DataFrame(details)

def comprehensive_backtest(df):
    log = []
    holding = False; entry_p = 0; entry_d = None
    for i in range(20, len(df)):
        r = df.iloc[i]; prev = df.iloc[i-1]
        if not holding and r['Close'] > r['MA20'] and r['OSC'] > 0:
            holding = True; entry_p = r['Close']; entry_d = df.index[i]
        elif holding and (r['Close'] < r['MA20'] or r['RSI'] > 85):
            log.append({"é€²å ´": entry_d.date(), "å‡ºå ´": df.index[i].date(), "è²·å…¥": entry_p, "è³£å‡º": r['Close'], "ç²åˆ©%": (r['Close']-entry_p)/entry_p*100})
            holding = False
    return pd.DataFrame(log)
