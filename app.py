import streamlit as st
import pandas as pd
import yfinance as yf
import numpy as np
import google.generativeai as genai
from duckduckgo_search import DDGS
import time

# ==========================================
# ðŸ”§ è¨­å®šé é¢
# ==========================================
st.set_page_config(page_title="å…¨çƒè‚¡å¸‚ AI æˆ°æƒ…å®¤ (Gemini 2.5 ç‰ˆ)", page_icon="ðŸ“¡", layout="wide")

# åˆå§‹åŒ– Session State
if "messages" not in st.session_state:
    st.session_state.messages = []
if "stock_cache" not in st.session_state:
    st.session_state.stock_cache = None

# ==========================================
# ðŸŒ ç¶²è·¯æœå°‹åŠŸèƒ½ (DuckDuckGo)
# ==========================================
def search_web(keyword, max_results=5):
    """ä½¿ç”¨ DuckDuckGo æœå°‹å³æ™‚è²¡ç¶“æ–°èž"""
    try:
        results = []
        # ä½¿ç”¨ context manager ç¢ºä¿è³‡æºé‡‹æ”¾
        with DDGS() as ddgs:
            search_query = f"{keyword} stock news finance"
            # æœå°‹ä¸¦ç²å–çµæžœ
            ddgs_gen = ddgs.text(search_query, max_results=max_results)
            for r in ddgs_gen:
                results.append(f"æ¨™é¡Œ: {r['title']}\né€£çµ: {r['href']}\næ‘˜è¦: {r['body']}")
        
        return "\n\n".join(results) if results else "æŸ¥ç„¡ç›¸é—œå³æ™‚æ–°èžã€‚"
    except Exception as e:
        print(f"æœå°‹éŒ¯èª¤: {e}")
        return "âš ï¸ æœå°‹åŠŸèƒ½æš«æ™‚å—é™ (è«‹ç¨å¾Œå†è©¦)ã€‚"

# ==========================================
# ðŸ“Š æ•¸æ“šç²å–èˆ‡è¨ˆç®—
# ==========================================
def calculate_technical_indicators(df):
    """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™"""
    # å‡ç·š
    df['MA5'] = df['Close'].rolling(5).mean()
    df['MA20'] = df['Close'].rolling(20).mean()
    df['MA60'] = df['Close'].rolling(60).mean()
    
    # MACD
    ema12 = df['Close'].ewm(span=12, adjust=False).mean()
    ema26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['DIF'] = ema12 - ema26
    df['MACD'] = df['DIF'].ewm(span=9, adjust=False).mean()
    
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / loss.replace(0, np.nan)
    df['RSI'] = 100 - (100 / (1 + rs))
    
    return df

@st.cache_data(ttl=300)
def get_stock_data(ticker):
    """ä¸‹è¼‰è‚¡åƒ¹ä¸¦ç²å–å…¬å¸åç¨±"""
    ticker = ticker.strip().upper()
    
    # æ™ºæ…§åˆ¤æ–·å°è‚¡å¾Œç¶´
    if ticker.isdigit():
        ticker = f"{ticker}.TW"
    
    try:
        stock = yf.Ticker(ticker)
        df = stock.history(period="1y")
        
        if df.empty:
            return None, None, "âŒ æŸ¥ç„¡æ­¤è‚¡ç¥¨æ•¸æ“šï¼Œè«‹ç¢ºèªä»£è™Ÿ (å¦‚: 2330.TW, AAPL)"
        
        try:
            info = stock.info
            company_name = info.get('longName') or info.get('shortName') or ticker
        except:
            company_name = ticker

        df = calculate_technical_indicators(df)
        return df, {"name": company_name, "ticker": ticker}, None
        
    except Exception as e:
        return None, None, str(e)

# ==========================================
# ðŸ§  AI æ ¸å¿ƒ (ä½¿ç”¨ Gemini 2.5 Flash)
# ==========================================
def chat_with_gemini(api_key, user_input, stock_context, news_context, system_prompt):
    if not api_key: return "âš ï¸ è«‹è¼¸å…¥ Google API Key"
    
    genai.configure(api_key=api_key)
    
    full_prompt = f"""
    ã€ä½¿ç”¨è€…å•é¡Œã€‘: {user_input}
    
    ã€ç•¶å‰è‚¡ç¥¨å³æ™‚æ•¸æ“šã€‘:
    {stock_context}
    
    ã€ç¶²è·¯æœå°‹åˆ°çš„å³æ™‚æ–°èž/å¸‚å ´æ¶ˆæ¯ã€‘:
    {news_context}
    
    è«‹æ ¹æ“šä»¥ä¸ŠçœŸå¯¦æ•¸æ“šèˆ‡æ–°èžï¼Œé€²è¡Œå°ˆæ¥­åœ˜éšŠçš„è¾¯è­‰èˆ‡åˆ†æžã€‚
    """

    # ðŸ”´ é—œéµä¿®æ”¹ï¼šä½¿ç”¨æ‚¨è¨ºæ–·å‡ºä¾†çš„æ­£ç¢ºæ¨¡åž‹åç¨±
    # æ ¹æ“šæ‚¨çš„æ¸…å–®ï¼Œé€™æ˜¯ index 0 çš„æ¨¡åž‹
    model_name = "models/gemini-2.5-flash" 
    
    try:
        model = genai.GenerativeModel(model_name, system_instruction=system_prompt)
        
        # åŠ å…¥é‡è©¦æ©Ÿåˆ¶ï¼Œå› ç‚º 2.5 Flash æ˜¯é è¦½ç‰ˆï¼Œå¯èƒ½æœ‰é »çŽ‡é™åˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = model.generate_content(full_prompt)
                return response.text
            except Exception as e:
                error_msg = str(e)
                if "429" in error_msg: # é…é¡ä¸è¶³
                    wait_time = 5 * (attempt + 1)
                    print(f"âš ï¸ è§¸ç™¼ API é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...")
                    time.sleep(wait_time)
                    continue
                else:
                    raise e # å…¶ä»–éŒ¯èª¤ç›´æŽ¥æ‹‹å‡º

    except Exception as e:
        return f"âŒ AI åˆ†æžéŒ¯èª¤ ({model_name}): {str(e)}"
    
    return "âš ï¸ ç³»çµ±ç¹å¿™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

# ==========================================
# ðŸ–¥ï¸ UI ä»‹é¢
# ==========================================
st.title("ðŸ“¡ å…¨çƒè‚¡å¸‚ AI æˆ°æƒ…å®¤ (Gemini 2.5 æ ¸å¿ƒ)")
st.caption("ðŸš€ ä½¿ç”¨æœ€æ–° Google Gemini 2.5 Flash æ¨¡åž‹é©…å‹•")

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    st.markdown("### ðŸ” è¼¸å…¥ä»£è™Ÿ")
    st.text("ç¯„ä¾‹ï¼š2330, AAPL, TSLA, 0050")
    ticker_input = st.text_input("è‚¡ç¥¨ä»£è™Ÿ", value="2330")
    
    if st.button("ðŸš€ å•Ÿå‹•åˆ†æž", type="primary"):
        if not api_key:
            st.error("è«‹å…ˆè¼¸å…¥ API Keyï¼")
        else:
            st.session_state.messages = [] 
            st.session_state.stock_cache = None 
            
            with st.spinner(f"æ­£åœ¨é€£ç·šäº¤æ˜“æ‰€èˆ‡æœå°‹ {ticker_input} æœ€æ–°æ–°èž..."):
                df, info, err = get_stock_data(ticker_input)
                
                if df is not None:
                    # 1. æœå°‹ç¶²è·¯æ–°èž
                    news_text = search_web(f"{info['name']} {info['ticker']}")
                    
                    # 2. æ•´ç†æ•¸æ“šæ–‡æœ¬
                    latest = df.iloc[-1]
                    stock_context_str = f"""
                    è‚¡ç¥¨: {info['name']} ({info['ticker']})
                    æ”¶ç›¤åƒ¹: {latest['Close']:.2f}
                    MA5: {latest['MA5']:.2f} | MA20: {latest['MA20']:.2f} | MA60: {latest['MA60']:.2f}
                    RSI: {latest['RSI']:.2f} | MACD: {latest['MACD']:.2f}
                    """
                    
                    # 3. å­˜å…¥ Session
                    st.session_state.stock_cache = {
                        "df": df,
                        "info": info,
                        "news": news_text,
                        "context_str": stock_context_str
                    }
                    
                    # 4. è§¸ç™¼ AI ç¬¬ä¸€å¥è©±
                    initial_prompt = "è«‹æ ¹æ“šå‚³å…¥çš„æ•¸æ“šèˆ‡æ–°èžï¼Œå°é€™æª”è‚¡ç¥¨é€²è¡Œä¸€æ¬¡å®Œæ•´çš„ã€ŒèŽŠå®¶åœ˜éšŠã€å¤šè§’åº¦åˆ†æžã€‚"
                    
                    system_instruction = """
                    ä½ æ˜¯ä¸€å€‹ç”±ã€Œç¸½é«”ç¶“æ¿Ÿå¸«ã€æŠ€è¡“åˆ†æžå¸«ã€èŽŠå®¶æ“ç›¤æ‰‹ã€å·´è²ç‰¹ã€çµ„æˆçš„æŠ•è³‡åœ˜éšŠã€‚
                    è«‹å¼•ç”¨æ–°èžä¸¦ç”¨é™°è¬€è«–è¦–è§’è§£è®€ï¼Œæœ€å¾Œçµ¦å‡ºæ˜Žç¢ºæ“ä½œå»ºè­°ã€‚
                    """
                    
                    ai_reply = chat_with_gemini(api_key, initial_prompt, stock_context_str, news_text, system_instruction)
                    st.session_state.messages.append({"role": "assistant", "content": ai_reply})
                    
                else:
                    st.error(err)

# === ä¸»è¦é¡¯ç¤ºå€ ===

if st.session_state.stock_cache:
    cache = st.session_state.stock_cache
    df = cache['df']
    info = cache['info']
    
    # é¡¯ç¤ºåŸºæœ¬è³‡è¨Š
    col1, col2 = st.columns([1, 3])
    with col1:
        st.metric(f"{info['name']}", f"{df.iloc[-1]['Close']:.2f}", f"{df.iloc[-1]['Close'] - df.iloc[-2]['Close']:.2f}")
    with col2:
        st.info(f"ðŸ“° **å·²ç²å–æœ€æ–°ç¶²è·¯æƒ…å ±**ï¼š\n{cache['news'][:150]}...")

    # é¡¯ç¤ºåœ–è¡¨
    st.line_chart(df['Close'])

    # å°è©±å€
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ä½¿ç”¨è€…è¼¸å…¥
    if user_input := st.chat_input("è¿½å• AI (ä¾‹å¦‚ï¼šé€™å‰‡æ–°èžå°æ˜Žå¤©è‚¡åƒ¹æœ‰ä»€éº¼å½±éŸ¿ï¼Ÿ)"):
        st.chat_message("user").markdown(user_input)
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        with st.spinner("AI åœ˜éšŠæ­£åœ¨æ ¹æ“šæ–°èžè¾¯è­‰ä¸­..."):
            system_instruction = "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­è‚¡ç¥¨åˆ†æžåœ˜éšŠï¼Œè«‹æ ¹æ“šå·²æœ‰çš„æ•¸æ“šèˆ‡æ–°èžå›žç­”ç”¨æˆ¶å•é¡Œã€‚"
            response = chat_with_gemini(api_key, user_input, cache['context_str'], cache['news'], system_instruction)
            
            st.chat_message("assistant").markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})

else:
    st.info("ðŸ‘ˆ è«‹åœ¨å·¦å´è¼¸å…¥ API Key èˆ‡ è‚¡ç¥¨ä»£è™Ÿä¸¦é»žæ“Šã€Œå•Ÿå‹•åˆ†æžã€")
