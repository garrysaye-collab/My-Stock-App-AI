import streamlit as st
import pandas as pd
import yfinance as yf
import numpy as np
import google.generativeai as genai
from duckduckgo_search import DDGS
import time

# ==========================================
# ðŸ”§ è¨­å®šé é¢
# ==========================================
st.set_page_config(page_title="å…¨çƒè‚¡å¸‚ AI æˆ°æƒ…å®¤ (çµ‚æ¥µä¿®å¾©ç‰ˆ)", page_icon="ðŸ“¡", layout="wide")

# åˆå§‹åŒ– Session State
if "messages" not in st.session_state:
    st.session_state.messages = []
if "stock_cache" not in st.session_state:
    st.session_state.stock_cache = None

# ==========================================
# ðŸŒ ç¶²è·¯æœå°‹åŠŸèƒ½
# ==========================================
def search_web(keyword, max_results=5):
    """ä½¿ç”¨ DuckDuckGo æœå°‹å³æ™‚è²¡ç¶“æ–°èž"""
    try:
        results = []
        with DDGS() as ddgs:
            search_query = f"{keyword} stock news finance"
            ddgs_gen = ddgs.text(search_query, max_results=max_results)
            for r in ddgs_gen:
                results.append(f"æ¨™é¡Œ: {r['title']}\né€£çµ: {r['href']}\næ‘˜è¦: {r['body']}")
        
        return "\n\n".join(results) if results else "æŸ¥ç„¡ç›¸é—œå³æ™‚æ–°èžã€‚"
    except Exception as e:
        return f"æœå°‹åŠŸèƒ½æš«æ™‚ç„¡æ³•ä½¿ç”¨ (å¯èƒ½æ˜¯é »çŽ‡é™åˆ¶): {str(e)}"

# ==========================================
# ðŸ“Š æ•¸æ“šç²å–èˆ‡è¨ˆç®—
# ==========================================
def calculate_technical_indicators(df):
    """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™"""
    # å‡ç·š
    df['MA5'] = df['Close'].rolling(5).mean()
    df['MA20'] = df['Close'].rolling(20).mean()
    df['MA60'] = df['Close'].rolling(60).mean()
    
    # MACD
    ema12 = df['Close'].ewm(span=12, adjust=False).mean()
    ema26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['DIF'] = ema12 - ema26
    df['MACD'] = df['DIF'].ewm(span=9, adjust=False).mean()
    
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / loss.replace(0, np.nan)
    df['RSI'] = 100 - (100 / (1 + rs))
    
    return df

@st.cache_data(ttl=300)
def get_stock_data(ticker):
    """ä¸‹è¼‰è‚¡åƒ¹ä¸¦ç²å–å…¬å¸åç¨±"""
    ticker = ticker.strip().upper()
    
    # æ™ºæ…§åˆ¤æ–·å¾Œç¶´
    if ticker.isdigit():
        ticker = f"{ticker}.TW"
    
    try:
        stock = yf.Ticker(ticker)
        df = stock.history(period="1y")
        
        if df.empty:
            return None, None, "âŒ æŸ¥ç„¡æ­¤è‚¡ç¥¨æ•¸æ“šï¼Œè«‹ç¢ºèªä»£è™Ÿ (å¦‚: 2330.TW, 600900.SS, AAPL)"
        
        try:
            info = stock.info
            company_name = info.get('longName') or info.get('shortName') or ticker
            currency = info.get('currency', 'Unknown')
        except:
            company_name = ticker
            currency = "?"

        df = calculate_technical_indicators(df)
        return df, {"name": company_name, "currency": currency, "ticker": ticker}, None
        
    except Exception as e:
        return None, None, str(e)

# ==========================================
# ðŸ§  AI æ ¸å¿ƒ (å«è‡ªå‹•æ¨¡åž‹åˆ‡æ›èˆ‡é‡è©¦)
# ==========================================
def chat_with_gemini(api_key, user_input, stock_context, news_context, system_prompt):
    if not api_key: return "âš ï¸ è«‹è¼¸å…¥ Google API Key"
    
    genai.configure(api_key=api_key)
    
    full_prompt = f"""
    ã€ä½¿ç”¨è€…å•é¡Œã€‘: {user_input}
    
    ã€ç•¶å‰è‚¡ç¥¨å³æ™‚æ•¸æ“šã€‘:
    {stock_context}
    
    ã€ç¶²è·¯æœå°‹åˆ°çš„å³æ™‚æ–°èž/å¸‚å ´æ¶ˆæ¯ã€‘:
    {news_context}
    
    è«‹æ ¹æ“šä»¥ä¸ŠçœŸå¯¦æ•¸æ“šèˆ‡æ–°èžï¼Œé€²è¡Œå°ˆæ¥­åœ˜éšŠçš„è¾¯è­‰èˆ‡åˆ†æžã€‚
    """

    # å®šç¾©æ¨¡åž‹å„ªå…ˆé †åºï¼šå…ˆè©¦ Flash (å¿«ä¸”æ–°)ï¼Œä¸è¡Œå°±æ› Pro (èˆŠä½†ç©©å®š)
    models_to_try = ['gemini-1.5-flash', 'gemini-pro']
    
    last_error = ""

    for model_name in models_to_try:
        try:
            # å»ºç«‹æ¨¡åž‹
            model = genai.GenerativeModel(model_name, system_instruction=system_prompt)
            
            # é‡è©¦æ©Ÿåˆ¶ (è™•ç† 429 Rate Limit)
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    response = model.generate_content(full_prompt)
                    return response.text # æˆåŠŸå°±ç›´æŽ¥å›žå‚³
                except Exception as e:
                    error_msg = str(e)
                    if "429" in error_msg: # å¦‚æžœæ˜¯é…é¡é™åˆ¶
                        time.sleep(5 * (attempt + 1)) # ç­‰å¾…å¾Œé‡è©¦
                        continue
                    elif "404" in error_msg or "not found" in error_msg.lower():
                        # å¦‚æžœæ˜¯æ‰¾ä¸åˆ°æ¨¡åž‹ (404)ï¼Œè·³å‡ºå…§å±¤è¿´åœˆï¼Œè®“å¤–å±¤è¿´åœˆæ›ä¸‹ä¸€å€‹æ¨¡åž‹
                        raise Exception("Model Not Found") 
                    else:
                        raise e # å…¶ä»–éŒ¯èª¤ç›´æŽ¥æ‹‹å‡º

        except Exception as e:
            last_error = str(e)
            if "Model Not Found" in str(e):
                print(f"âš ï¸ æ¨¡åž‹ {model_name} ç„¡æ³•ä½¿ç”¨ï¼Œå˜—è©¦åˆ‡æ›è‡³ä¸‹ä¸€å€‹æ¨¡åž‹...")
                continue # æ›ä¸‹ä¸€å€‹æ¨¡åž‹
            else:
                # å¦‚æžœæ˜¯å…¶ä»–åš´é‡éŒ¯èª¤ï¼Œå°±ä¸æ›æ¨¡åž‹äº†ï¼Œç›´æŽ¥å›žå ±
                return f"âŒ AI åˆ†æžéŒ¯èª¤ ({model_name}): {str(e)}"
    
    return f"âŒ æ‰€æœ‰æ¨¡åž‹å˜—è©¦çš†å¤±æ•—ã€‚æœ€å¾ŒéŒ¯èª¤: {last_error}"

# ==========================================
# ðŸ–¥ï¸ UI ä»‹é¢
# ==========================================
st.title("ðŸ“¡ å…¨çƒè‚¡å¸‚ AI æˆ°æƒ…å®¤")
st.caption("è‡ªå‹•åˆ‡æ›æ¨¡åž‹ç‰ˆï¼šå„ªå…ˆä½¿ç”¨ Flashï¼Œè‡ªå‹•é™ç´šè‡³ Pro")

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    ticker_input = st.text_input("è¼¸å…¥ä»£è™Ÿ (å¦‚ 2330, AAPL)", value="2330")
    
    if st.button("ðŸš€ å•Ÿå‹•åˆ†æž", type="primary"):
        if not api_key:
            st.error("è«‹å…ˆè¼¸å…¥ API Keyï¼")
        else:
            st.session_state.messages = [] 
            st.session_state.stock_cache = None 
            
            with st.spinner(f"æ­£åœ¨é€£ç·šäº¤æ˜“æ‰€èˆ‡æœå°‹ {ticker_input} æœ€æ–°æ–°èž..."):
                df, info, err = get_stock_data(ticker_input)
                
                if df is not None:
                    # 1. æœå°‹ç¶²è·¯æ–°èž
                    news_text = search_web(f"{info['name']} {info['ticker']}")
                    
                    # 2. æ•´ç†æ•¸æ“šæ–‡æœ¬
                    latest = df.iloc[-1]
                    stock_context_str = f"""
                    è‚¡ç¥¨: {info['name']} ({info['ticker']})
                    æ”¶ç›¤åƒ¹: {latest['Close']:.2f}
                    MA5: {latest['MA5']:.2f} | MA20: {latest['MA20']:.2f} | MA60: {latest['MA60']:.2f}
                    RSI: {latest['RSI']:.2f} | MACD: {latest['MACD']:.2f}
                    """
                    
                    # 3. å­˜å…¥ Session
                    st.session_state.stock_cache = {
                        "df": df,
                        "info": info,
                        "news": news_text,
                        "context_str": stock_context_str
                    }
                    
                    # 4. è§¸ç™¼ AI
                    initial_prompt = "è«‹æ ¹æ“šå‚³å…¥çš„æ•¸æ“šèˆ‡æ–°èžï¼Œå°é€™æª”è‚¡ç¥¨é€²è¡Œä¸€æ¬¡å®Œæ•´çš„ã€ŒèŽŠå®¶åœ˜éšŠã€å¤šè§’åº¦åˆ†æžã€‚"
                    system_instruction = "ä½ æ˜¯ä¸€å€‹ç”±ã€Œç¸½é«”ç¶“æ¿Ÿå¸«ã€æŠ€è¡“åˆ†æžå¸«ã€èŽŠå®¶æ“ç›¤æ‰‹ã€å·´è²ç‰¹ã€çµ„æˆçš„æŠ•è³‡åœ˜éšŠã€‚è«‹å¼•ç”¨æ–°èžä¸¦ç”¨é™°è¬€è«–è¦–è§’è§£è®€ã€‚"
                    
                    ai_reply = chat_with_gemini(api_key, initial_prompt, stock_context_str, news_text, system_instruction)
                    st.session_state.messages.append({"role": "assistant", "content": ai_reply})
                    
                else:
                    st.error(err)

# === ä¸»è¦é¡¯ç¤ºå€ ===

if st.session_state.stock_cache:
    cache = st.session_state.stock_cache
    df = cache['df']
    info = cache['info']
    
    col1, col2 = st.columns([1, 3])
    with col1:
        st.metric(f"{info['name']}", f"{df.iloc[-1]['Close']:.2f}")
    with col2:
        st.info(f"ðŸ“° **ç¶²è·¯æ–°èžæ‘˜è¦**ï¼š\n{cache['news'][:150]}...")

    st.line_chart(df['Close'])

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if user_input := st.chat_input("è¿½å• AI..."):
        st.chat_message("user").markdown(user_input)
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        with st.spinner("AI åœ˜éšŠæ€è€ƒä¸­..."):
            system_instruction = "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­è‚¡ç¥¨åˆ†æžåœ˜éšŠã€‚"
            response = chat_with_gemini(api_key, user_input, cache['context_str'], cache['news'], system_instruction)
            
            st.chat_message("assistant").markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
